{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KMR8h1fm7Zc",
        "outputId": "8fb173ee-dc4b-4d1c-cf94-f0b8a3cba0d8"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "0GwYTkgvXpKl"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "qK8If-zYc5IN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "# tf.config.experimental_connect_to_cluster(resolver)\n",
        "# # This is the TPU initialization code that has to be at the beginning.\n",
        "# tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "# print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "# strategy = tf.distribute.TPUStrategy(resolver)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q git+https://github.com/tensorflow/docs"
      ],
      "metadata": {
        "id": "Bqiq47ZMnNGZ"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow_docs.vis import embed\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "import gc\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "import os\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3"
      ],
      "metadata": {
        "id": "C5DmtyLcdz6l"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
        "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) "
      ],
      "metadata": {
        "id": "o7aciQPHylji"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
      ],
      "metadata": {
        "id": "frw_81G0bMVW"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def changePath(row):\n",
        "  path=row[\"Path\"]\n",
        "  path=path.replace(\"Transformer_1\",\"dcsass\")\n",
        "  return path"
      ],
      "metadata": {
        "id": "AvXrGO0k6ur2"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv=pd.read_csv(\"/content/drive/MyDrive/tf_transformer_4/data.csv\")\n",
        "csv=csv[csv['exists']==True]\n",
        "csv=csv[csv['classLabel']<=15]"
      ],
      "metadata": {
        "id": "L6VJBbr3d1OT"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "trainCsv=pd.DataFrame()\n",
        "valCsv=pd.DataFrame()\n",
        "testCsv=pd.DataFrame()\n",
        "n_of_each_class=400\n",
        "csv=csv[csv['exists']==True]\n",
        "csv=csv[csv['classLabel']<=15]\n",
        "csv[\"Path\"]=csv.apply(lambda row:changePath(row),axis=1)"
      ],
      "metadata": {
        "id": "-WP2By-FesNH"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# csv[csv[\"label\"]==0]"
      ],
      "metadata": {
        "id": "tQlBVbt5ao-R"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# n_classes=len((csv['classLabel'].unique()))\n",
        "# print(sorted((csv['classLabel'].unique())))\n",
        "# for Class in sorted((csv['classLabel'].unique())):\n",
        "#   t1=len(csv[csv['classLabel']==Class])\n",
        "#   t,v=train_test_split(csv[csv['classLabel']==Class].sample(min(t1,n_of_each_class)),test_size=0.30)\n",
        "#   v1,tes=train_test_split(v[v['classLabel']==Class],test_size=1/3)\n",
        "#   trainCsv=pd.concat((trainCsv,t))\n",
        "#   testCsv=pd.concat((testCsv,tes))\n",
        "#   valCsv=pd.concat((valCsv,v1))"
      ],
      "metadata": {
        "id": "QlU3yA0z6nb6"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "option=\"classLabel\"\n",
        "# option=\"label\"\n",
        "n_classes=len((csv[option].unique()))\n",
        "print(sorted((csv['classLabel'].unique())))\n",
        "for Class in sorted((csv['class'].unique())):\n",
        "  # t1=len(csv[csv['classLabel']==Class])\n",
        "  chunk0=csv[(csv['class']==Class)&(csv['label']==0.0)]\n",
        "  t0=len(chunk0)\n",
        "  chunk1=csv[(csv['class']==Class)&(csv['label']==1.0)]\n",
        "  t1=len(chunk1)\n",
        "  chunk=pd.concat([chunk0.sample(min(t1,min(t0,n_of_each_class//2))),chunk1.sample(min(t1,n_of_each_class//2))])\n",
        "  # chunk=pd.concat([chunk0.sample(min(0,min(t0,n_of_each_class//2))),chunk1.sample(min(t1,n_of_each_class//2))])\n",
        "  t,v=train_test_split(chunk,test_size=0.30)\n",
        "  v1,tes=train_test_split(v,test_size=1/3)\n",
        "  trainCsv=pd.concat((trainCsv,t))\n",
        "  testCsv=pd.concat((testCsv,tes))\n",
        "  valCsv=pd.concat((valCsv,v1))\n",
        "class_count_dict=dict()\n",
        "max_class=0\n",
        "for Class in trainCsv[option].unique():\n",
        "  t=len(trainCsv[trainCsv[option]==Class])\n",
        "  max_class=max(max_class,t)\n",
        "for Class in trainCsv[option].unique():\n",
        "  t=len(trainCsv[trainCsv[option]==Class])\n",
        "  class_count_dict[Class]=max_class/t\n",
        "print(class_count_dict)\n",
        "trainCsv = shuffle(trainCsv)\n",
        "testCsv = shuffle(testCsv)\n",
        "valCsv = shuffle(valCsv)\n",
        "print(len(trainCsv))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BofmDUn9YcLO",
        "outputId": "1f331d53-f1b6-43e3-fff9-b19ac71e01ab"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0]\n",
            "{0.0: 1.0, 1.0: 12.511111111111111, 3.0: 12.511111111111111, 2.0: 11.97872340425532, 5.0: 11.811188811188812, 11.0: 12.151079136690647, 13.0: 14.313559322033898, 10.0: 28.15, 8.0: 12.23913043478261, 9.0: 12.699248120300751, 6.0: 11.648275862068965, 4.0: 14.81578947368421, 12.0: 12.419117647058824, 7.0: 12.795454545454545}\n",
            "3358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for Class in csv[\"class\"].unique():\n",
        "  print(len(trainCsv[(trainCsv[\"label\"]==0)&(trainCsv[\"class\"]==Class)]))\n",
        "  print(len(trainCsv[(trainCsv[\"label\"]==1)&(trainCsv[\"class\"]==Class)]))\n",
        "  print(\"-------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ8t97K94fys",
        "outputId": "ed13e0a0-c7c2-4c17-ce34-675792072a98"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "145\n",
            "135\n",
            "-------\n",
            "139\n",
            "141\n",
            "-------\n",
            "145\n",
            "135\n",
            "-------\n",
            "103\n",
            "114\n",
            "-------\n",
            "137\n",
            "143\n",
            "-------\n",
            "135\n",
            "145\n",
            "-------\n",
            "148\n",
            "132\n",
            "-------\n",
            "142\n",
            "138\n",
            "-------\n",
            "147\n",
            "133\n",
            "-------\n",
            "60\n",
            "60\n",
            "-------\n",
            "141\n",
            "139\n",
            "-------\n",
            "144\n",
            "136\n",
            "-------\n",
            "103\n",
            "118\n",
            "-------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(trainCsv[trainCsv[\"label\"]==0]))\n",
        "print(len(trainCsv[trainCsv[\"label\"]==1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcS9NTQ7adAj",
        "outputId": "b1aae432-a9d4-4798-b818-d1fb74143996"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1689\n",
            "1669\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frameSize=(128,128)\n",
        "nFrames=45\n",
        "# defFrame=(300,300)\n",
        "batch_size=32#8\n",
        "vals_batch_size=32#8\n",
        "params = {'batch_size': batch_size,\n",
        "          'frameSize': frameSize,\n",
        "          # 'frameSize': defFrame,\n",
        "          'nFrames': nFrames,\n",
        "          'nclasses': n_classes,\n",
        "          'oneHotEncode': True,\n",
        "          'shuffle': True, \n",
        "          'normalize': False,\n",
        "          'std':False}\n",
        "val_params={'batch_size': vals_batch_size,\n",
        "          'frameSize': frameSize,\n",
        "          # 'frameSize': defFrame,\n",
        "          'nFrames': nFrames,\n",
        "          'nclasses': n_classes,\n",
        "          'oneHotEncode': True,\n",
        "          'shuffle': True, \n",
        "          'normalize': False,\n",
        "          'std':False}"
      ],
      "metadata": {
        "id": "yyw_GM0EfEZn"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade ipyparallel\n",
        "!ipcluster start -n 24"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptQ9yJyFoBCz",
        "outputId": "8e9f2abf-09b8-4f73-d285-3539f903e366"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipyparallel in /usr/local/lib/python3.7/dist-packages (8.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3 in /usr/local/lib/python3.7/dist-packages (from ipyparallel) (5.1.1)\n",
            "Requirement already satisfied: pyzmq>=18 in /usr/local/lib/python3.7/dist-packages (from ipyparallel) (22.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipyparallel) (4.4.2)\n",
            "Requirement already satisfied: ipython>=4 in /usr/local/lib/python3.7/dist-packages (from ipyparallel) (5.5.0)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from ipyparallel) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipyparallel) (5.3.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from ipyparallel) (5.4.8)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from ipyparallel) (2.8.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from ipyparallel) (0.4)\n",
            "Requirement already satisfied: ipykernel>=4.4 in /usr/local/lib/python3.7/dist-packages (from ipyparallel) (4.10.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ipyparallel) (4.62.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4->ipyparallel) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4->ipyparallel) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4->ipyparallel) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4->ipyparallel) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4->ipyparallel) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4->ipyparallel) (0.8.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4->ipyparallel) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4->ipyparallel) (0.2.5)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipyparallel) (4.9.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=4->ipyparallel) (0.7.0)\n",
            "2022-02-07 16:12:19.010 [IPClusterStart] Using existing profile dir: '/root/.ipython/profile_default'\n",
            "2022-02-07 16:12:19.643 [IPClusterStart] CRITICAL | Cluster is already running at /root/.ipython/profile_default/security/cluster-.json. use `ipcluster stop` to stop the cluster.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainCsv[\"Path\"].iloc[[0]].item()"
      ],
      "metadata": {
        "id": "tEKAOKUv6AG3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d26258a6-7899-4fa9-e6fa-14c89eb6473e"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/dcsass/DCSASS Dataset/Explosion/Explosion052_x264.mp4/Explosion052_x264_17.mp4'"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from ipyparallel import Client\n",
        "# with tf.device(\"/device:GPU:0\"): \n",
        "# # with strategy.scope(): \n",
        "#   cli = Client()\n",
        "#   dview = cli[:]\n",
        "#   @dview.parallel(block=True)\n",
        "#   def loadData(i,index,listPaths,labels,nFrames,frameSize):\n",
        "#     import numpy as np\n",
        "#     import cv2,gc\n",
        "#     path = listPaths[index]\n",
        "#     try:\n",
        "#       vidcap=cv2.VideoCapture(path)\n",
        "#       totalFrames=int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "#       # print(totalFrames)\n",
        "#       if totalFrames>=nFrames:\n",
        "#         focusFrames=np.linspace(0,totalFrames-1,nFrames).astype(int)\n",
        "#         # assert len(focusFrames) == len(set(focusFrames))\n",
        "#         success=True\n",
        "#         imgsBundle=np.zeros((nFrames,frameSize[0],frameSize[1],3))\n",
        "#         i1=0\n",
        "#         countPush=0\n",
        "#         while success==True:\n",
        "#           success,image = vidcap.read()\n",
        "#           if i1 in focusFrames:\n",
        "#             img=cv2.resize(image,frameSize)\n",
        "#             imgsBundle[countPush]=img\n",
        "#             # imgsBundle[countPush]=image\n",
        "#             countPush+=1\n",
        "#           if countPush==nFrames-1:\n",
        "#             break\n",
        "#           i1+=1\n",
        "#         gc.enable()\n",
        "#         gc.collect()\n",
        "#         labels1=labels[index]\n",
        "#       else:\n",
        "#         # pass\n",
        "#         imgsBundle=np.zeros((nFrames,frameSize[0],frameSize[1],3))\n",
        "#         i1=0\n",
        "#         countPush=0\n",
        "#         while success==True:\n",
        "#           success,image = vidcap.read()\n",
        "#           img=cv2.resize(image,frameSize)\n",
        "#           imgsBundle[countPush]=img\n",
        "#           # imgsBundle[countPush]=image\n",
        "#           countPush+=1\n",
        "#           i1+=1\n",
        "#         gc.enable()\n",
        "#         gc.collect()\n",
        "#         labels1=labels[index]\n",
        "#       return imgsBundle,labels1\n",
        "#     except:\n",
        "#       imgsBundle=np.zeros((nFrames,frameSize[0],frameSize[1],3))\n",
        "#       labels1=0\n",
        "#       gc.enable()\n",
        "#       gc.collect()\n",
        "#       print(\"Weird data\")\n",
        "#       return imgsBundle,labels1"
      ],
      "metadata": {
        "id": "cb2do3sxPVx9"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ipyparallel import Client\n",
        "with tf.device(\"/device:GPU:0\"): \n",
        "# with strategy.scope(): \n",
        "  cli = Client()\n",
        "  dview = cli[:]\n",
        "  @dview.parallel(block=True)\n",
        "  def loadData(i,index,listPaths,labels,nFrames,frameSize):\n",
        "    import numpy as np\n",
        "    import cv2,gc\n",
        "    path = listPaths[index]\n",
        "    try:\n",
        "      vidcap=cv2.VideoCapture(path)\n",
        "      totalFrames=int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "      print(totalFrames)\n",
        "      if totalFrames>=nFrames:\n",
        "        # print(\"Case 1\")\n",
        "        focusFrames=np.linspace(0,totalFrames-1,nFrames).astype(int)\n",
        "        # assert len(focusFrames) == len(set(focusFrames))\n",
        "        success=True\n",
        "        imgsBundle=np.zeros((nFrames,frameSize[0],frameSize[1],3))\n",
        "        i1=0\n",
        "        countPush=0\n",
        "        while success==True:\n",
        "          success,image = vidcap.read()\n",
        "          if success==False:\n",
        "            break\n",
        "          if i1 in focusFrames:\n",
        "            img=cv2.resize(image,frameSize)\n",
        "            imgsBundle[countPush]=img\n",
        "            # imgsBundle[countPush]=image\n",
        "            countPush+=1\n",
        "          if countPush==nFrames-1:\n",
        "            break\n",
        "          i1+=1\n",
        "        gc.enable()\n",
        "        gc.collect()\n",
        "        labels1=labels[index]\n",
        "      else:\n",
        "        # pass\n",
        "        print(\"Case 2\")\n",
        "        imgsBundle=np.zeros((nFrames,frameSize[0],frameSize[1],3))\n",
        "        i1=0\n",
        "        countPush=0\n",
        "        success=True\n",
        "        while success==True:\n",
        "          success,image = vidcap.read()\n",
        "          if success==False:\n",
        "            break\n",
        "          # print(\"Got here: \",countPush)\n",
        "          img=cv2.resize(image,frameSize)\n",
        "          imgsBundle[countPush]=img\n",
        "          # imgsBundle[countPush]=image\n",
        "          countPush+=1\n",
        "          i1+=1\n",
        "        gc.enable()\n",
        "        gc.collect()\n",
        "        labels1=labels[index]\n",
        "      return imgsBundle,labels1\n",
        "    except:\n",
        "      imgsBundle=np.zeros((nFrames,frameSize[0],frameSize[1],3))\n",
        "      labels1=0\n",
        "      gc.enable()\n",
        "      gc.collect()\n",
        "      print(\"Weird data\")\n",
        "      return imgsBundle,labels1"
      ],
      "metadata": {
        "id": "c8GYVwnuSJ3o"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i,row in trainCsv.iterrows():\n",
        "#   if os.path.exists(row[\"Path\"])==False:\n",
        "#     print(row[\"Path\"])"
      ],
      "metadata": {
        "id": "DTS1ltryPOnI"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(\"/device:GPU:0\"): \n",
        "# with strategy.scope(): \n",
        "  # cli = Client()\n",
        "  # dview = cli[:]\n",
        "  # @dview.parallel(block=True)\n",
        "  def loadDataTest(path,nFrames,frameSize):\n",
        "      import numpy as np\n",
        "      import cv2,gc\n",
        "      fine=True\n",
        "      try:\n",
        "        vidcap=cv2.VideoCapture(path)\n",
        "        totalFrames=int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        print(totalFrames)\n",
        "        fine=True\n",
        "        if totalFrames>=nFrames:\n",
        "          print(\"Case 1\")\n",
        "          focusFrames=np.linspace(0,totalFrames-1,nFrames).astype(int)\n",
        "          # assert len(focusFrames) == len(set(focusFrames))\n",
        "          success=True\n",
        "          imgsBundle=np.zeros((nFrames,frameSize[0],frameSize[1],3))\n",
        "          i1=0\n",
        "          countPush=0\n",
        "          while success==True:\n",
        "            success,image = vidcap.read()\n",
        "            if success==False:\n",
        "              break\n",
        "            if i1 in focusFrames:\n",
        "              img=cv2.resize(image,frameSize)\n",
        "              imgsBundle[countPush]=img\n",
        "              # imgsBundle[countPush]=image\n",
        "              countPush+=1\n",
        "            if countPush==nFrames-1:\n",
        "              break\n",
        "            i1+=1\n",
        "          gc.enable()\n",
        "          gc.collect()\n",
        "        else:\n",
        "          # pass\n",
        "          print(\"Case 2\")\n",
        "          imgsBundle=np.zeros((nFrames,frameSize[0],frameSize[1],3))\n",
        "          i1=0\n",
        "          countPush=0\n",
        "          success=True\n",
        "          while success==True:\n",
        "            success,image = vidcap.read()\n",
        "            if success==False:\n",
        "              break\n",
        "            # print(\"Got here: \",countPush)\n",
        "            img=cv2.resize(image,frameSize)\n",
        "            imgsBundle[countPush]=img\n",
        "            # imgsBundle[countPush]=image\n",
        "            countPush+=1\n",
        "            i1+=1\n",
        "          gc.enable()\n",
        "          gc.collect()\n",
        "\n",
        "      except:\n",
        "        fine=False\n",
        "        gc.enable()\n",
        "        gc.collect()\n",
        "        print(\"Weird data\")\n",
        "      print(\"-----------------\")\n",
        "      return fine"
      ],
      "metadata": {
        "id": "vgauaaJBPsXO"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fails=0\n",
        "# for i,row in trainCsv.iterrows():\n",
        "#   if loadDataTest(row[\"Path\"],nFrames,frameSize)==False:\n",
        "#     fails+=1\n",
        "# print(fails)"
      ],
      "metadata": {
        "id": "5x4e9DlCPvtB"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(\"/device:GPU:0\"): \n",
        "# with strategy.scope(): \n",
        "\n",
        "  class Dataset(keras.utils.Sequence):\n",
        "    'Characterizes a dataset for PyTorch'\n",
        "    def __init__(self, listPaths, labels,batch_size=10,nFrames=30,frameSize=(300,300),nclasses=2,shuffle=True,oneHotEncode=False,normalize=True,std=False):\n",
        "          'Initialization'\n",
        "          self.labels = labels\n",
        "          self.listPaths = listPaths\n",
        "          self.nFrames = nFrames\n",
        "          self.frameSize = frameSize\n",
        "          self.oneHotEncode = oneHotEncode\n",
        "          self.nclasses=nclasses\n",
        "          self.shuffle=shuffle\n",
        "          self.std=std\n",
        "          self.normalize=normalize\n",
        "          self.batch_size = batch_size\n",
        "          self.on_epoch_start()\n",
        "          # print('Data len',len(self.listPaths))\n",
        "\n",
        "    def __len__(self):\n",
        "      'Denotes the total number of samples'\n",
        "      #for example lets say we have 2000 videos for training and batch size is 40, then number of samples=2000/40=50\n",
        "      return int(np.floor(len(self.labels) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "      #since number of samples is 50 python will call this iterable using the __getitem__ function and index argument will go from 0 to 49\n",
        "      indexes = self.indexes[(index*self.batch_size):((index+1)*self.batch_size)]\n",
        "      Xx,Yx=self.__data_generation(indexes)\n",
        "      Xx=tf.convert_to_tensor(Xx)\n",
        "      Yx=tf.convert_to_tensor(Yx)\n",
        "      return Xx,Yx\n",
        "      \n",
        "    def on_epoch_start(self):\n",
        "      'Updates indexes after each epoch'\n",
        "      self.indexes = np.arange(len(self.labels))\n",
        "      if self.shuffle == True:\n",
        "          np.random.shuffle(self.indexes)\n",
        "    def __data_generation(self, indexes):\n",
        "      'Generates one sample of data'\n",
        "      # data=loadData.map([{i,index,self.listPaths,self.labels,self.nFrames,self.frameSize} for i,index in enumerate(indexes)])\n",
        "      data=loadData.map(range(len(indexes)),indexes,[self.listPaths]*len(indexes),[self.labels]*len(indexes),[self.nFrames]*len(indexes),[self.frameSize]*len(indexes))\n",
        "      # Y=np.asarray(data)[:,1]\n",
        "      Y=(np.asarray(data)[:,1]).astype(int)\n",
        "      X=np.stack(np.asarray(data)[:,0],axis=0)\n",
        "      if self.oneHotEncode==True:\n",
        "        # print(self.nclasses)\n",
        "        Y=keras.utils.to_categorical(Y,self.nclasses)\n",
        "      if self.std==True and np.std(X)!=0:\n",
        "        X=(X-np.mean(X))/np.std(X)\n",
        "      if self.normalize==True:\n",
        "        X=X/255\n",
        "      # print(\"Shape of output by data generator: \",np.shape(X),' ',np.shape(Y))\n",
        "      return X,Y"
      ],
      "metadata": {
        "id": "5mAV4XKmd5J1"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainCsv"
      ],
      "metadata": {
        "id": "OutiKjx_4zsX"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with strategy.scope(): \n",
        "with tf.device(\"/device:GPU:0\"): \n",
        "\n",
        "  training_generator = Dataset(listPaths=trainCsv['Path'].values, labels=trainCsv[option].values, **params)\n",
        "  val_generator = Dataset(listPaths=valCsv['Path'].values,labels= valCsv[option].values, **val_params)"
      ],
      "metadata": {
        "id": "1nCo9NFNg8nm"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from matplotlib import pyplot as plt\n",
        "# from google.colab.patches import cv2_imshow\n",
        "# failCount=0\n",
        "# total=0\n",
        "# consecutiveSuccess=0\n",
        "# for data_ in training_generator:\n",
        "#   # plt.imshow(data_[0][0][0], interpolation='nearest')\n",
        "#   total+=1\n",
        "#   if np.count_nonzero(data_[0])==0:\n",
        "#     failCount+=1\n",
        "#     consecutiveSuccess=0\n",
        "#   else:\n",
        "#     consecutiveSuccess+=1\n",
        "#   print(failCount,\" \",total)"
      ],
      "metadata": {
        "id": "fKLQvjqqUR_8"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with strategy.scope(): \n",
        "with tf.device(\"/device:GPU:0\"): \n",
        "  class PositionalEmbedding(layers.Layer):\n",
        "      def __init__(self, sequence_length, output_dim, **kwargs):\n",
        "          super().__init__(**kwargs)\n",
        "          self.position_embeddings = layers.Embedding(\n",
        "              input_dim=sequence_length, output_dim=output_dim\n",
        "          )\n",
        "          self.sequence_length = sequence_length\n",
        "          self.output_dim = output_dim\n",
        "\n",
        "      def call(self, inputs):\n",
        "          # The inputs are of shape: `(batch_size, frames, num_features)`\n",
        "          length = tf.shape(inputs)[1]\n",
        "          positions = tf.range(start=0, limit=length, delta=1)\n",
        "          embedded_positions = self.position_embeddings(positions)\n",
        "          return inputs + embedded_positions\n",
        "\n",
        "      def compute_mask(self, inputs, mask=None):\n",
        "          mask = tf.reduce_any(tf.cast(inputs, \"bool\"), axis=-1)\n",
        "          return mask"
      ],
      "metadata": {
        "id": "fYM_uvrJfXxN"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(\"/device:GPU:0\"): \n",
        "  class TFPositionalEncoding1D(tf.keras.layers.Layer):\n",
        "    def __init__(self, channels: int, dtype=tf.float32):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            channels int: The last dimension of the tensor you want to apply pos emb to.\n",
        "        Keyword Args:\n",
        "            dtype: output type of the encodings. Default is \"tf.float32\".\n",
        "        \"\"\"\n",
        "        super(TFPositionalEncoding1D, self).__init__()\n",
        "\n",
        "        self.channels = int(np.ceil(channels / 2) * 2)\n",
        "        self.inv_freq = np.float32(\n",
        "            1\n",
        "            / np.power(\n",
        "                10000, np.arange(0, self.channels, 2) / np.float32(self.channels)\n",
        "            )\n",
        "        )\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        :param tensor: A 3d tensor of size (batch_size, x, ch)\n",
        "        :return: Positional Encoding Matrix of size (batch_size, x, ch)\n",
        "        \"\"\"\n",
        "        if len(inputs.shape) != 3:\n",
        "            raise RuntimeError(\"The input tensor has to be 3d!\")\n",
        "        _, x, org_channels = inputs.shape\n",
        "\n",
        "        dtype = self.inv_freq.dtype\n",
        "        pos_x = tf.range(x, dtype=dtype)\n",
        "        sin_inp_x = tf.einsum(\"i,j->ij\", pos_x, self.inv_freq)\n",
        "        emb = tf.expand_dims(tf.concat((tf.sin(sin_inp_x), tf.cos(sin_inp_x)), -1), 0)\n",
        "        emb = emb[0]  # A bit of a hack\n",
        "        return tf.repeat(emb[None, :, :org_channels], tf.shape(inputs)[0], axis=0)"
      ],
      "metadata": {
        "id": "kmMtLNRf0rl3"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(\"/device:GPU:0\"): \n",
        "# with strategy.scope(): \n",
        "  def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0.5):\n",
        "      # Normalization and Attention\n",
        "      # x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "      x = layers.MultiHeadAttention(\n",
        "          key_dim=head_size, \n",
        "          num_heads=num_heads, \n",
        "          dropout=dropout,\n",
        "          # kernel_regularizer=tf.keras.regularizers.l1(0.02),\n",
        "          # activity_regularizer=tf.keras.regularizers.l1(0.01)\n",
        "      )(inputs, inputs)\n",
        "      x = layers.Dropout(dropout)(x)\n",
        "      res = x + inputs\n",
        "\n",
        "      # Feed Forward Part\n",
        "      # x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "      x = layers.Conv1D(filters=ff_dim, kernel_size=1,activation=tf.nn.gelu)(res)\n",
        "      # x = layers.Conv1D(filters=20, kernel_size=1, activation=\"relu\")(x)\n",
        "      # x = layers.Conv1D(filters=20, kernel_size=1, activation=\"relu\")(x)\n",
        "      x = layers.Dropout(dropout)(x)\n",
        "      x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "      return x + res"
      ],
      "metadata": {
        "id": "a3WPnWqByGZw"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(\"/device:GPU:0\"): \n",
        "  class TransformerEncoder(layers.Layer):\n",
        "      def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "          super().__init__(**kwargs)\n",
        "          self.embed_dim = embed_dim\n",
        "          self.dense_dim = dense_dim\n",
        "          self.num_heads = num_heads\n",
        "          self.attention = layers.MultiHeadAttention(\n",
        "              num_heads=num_heads, key_dim=embed_dim, dropout=0.3\n",
        "          )\n",
        "          self.dense_proj = keras.Sequential(\n",
        "              [layers.Dense(dense_dim, activation=tf.nn.gelu), layers.Dense(embed_dim, activation=tf.nn.gelu),]\n",
        "          )\n",
        "          # self.layernorm_1 = layers.LayerNormalization()\n",
        "          self.batchnorm_1 = layers.BatchNormalization()\n",
        "          # self.layernorm_2 = layers.LayerNormalization()\n",
        "          self.batchnorm_2 = layers.BatchNormalization()\n",
        "\n",
        "      def call(self, inputs, mask=None):\n",
        "          if mask is not None:\n",
        "              mask = mask[:, tf.newaxis, :]\n",
        "          inputs=self.batchnorm_1(inputs)\n",
        "          attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
        "          # proj_input = self.batchnorm_2(inputs + attention_output)\n",
        "          proj_input=(inputs + attention_output)\n",
        "          proj_output = self.dense_proj(proj_input)\n",
        "          # return self.batchnorm_2(proj_input + proj_output)\n",
        "          # return(inputs + attention_output)\n",
        "          # return proj_input\n",
        "          return proj_output+proj_input\n",
        "          # return attention_output"
      ],
      "metadata": {
        "id": "Asi_8SJJCvJu"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with strategy.scope(): \n",
        "with tf.device(\"/device:GPU:0\"): \n",
        "  def mainModel(seqLen=nFrames,embedDim=2048,numHeads=32,ff_dim=150,frameSize=frameSize,classes=2,dense_dim2=8,nTr=6,trDr=0.2,trDr2=0.2):\n",
        "    # print(\"INC model\")\n",
        "    # inputs = keras.Input(shape=(seqLen, frameSize[0], frameSize[1], 3))\n",
        "    inputs = keras.Input(shape=(seqLen, *(frameSize), 3))\n",
        "    print(inputs.shape)\n",
        "    # x=layers.TimeDistributed(layers.CenterCrop(*(frameSize)))(inputs)\n",
        "    # print(x.shape)\n",
        "    # x=layers.Lambda(lambda x:x/255)(inputs)\n",
        "    # x=keras.applications.inception_v3.preprocess_input(\n",
        "    #     inputs\n",
        "    # )\n",
        "    # x=keras.applications.inception_v3.preprocess_input(\n",
        "    #     inputs\n",
        "    # )\n",
        "    x=keras.applications.densenet.preprocess_input(inputs)\n",
        "    # inc=InceptionV3(include_top=False, pooling='avg',input_shape=(frameSize[0],frameSize[1],3))\n",
        "    inc=keras.applications.DenseNet121(weights=\"imagenet\",include_top=False,  pooling=\"max\",input_shape=(frameSize[0],frameSize[1],3))\n",
        "    # inc=tf.keras.applications.ResNet152V2(include_top=False, pooling='avg',input_shape=(frameSize[0],frameSize[1],3))\n",
        "    # inc=tf.keras.applications.DenseNet121(include_top=False, pooling='avg',input_shape=(frameSize[0],frameSize[1],3))\n",
        "    # inc.fc=layers.Dense(embedDim,activation=tf.nn.gelu)#is this line the issue?\n",
        "    for layer in inc.layers:\n",
        "      layer.trainable=False\n",
        "    x=layers.TimeDistributed(inc)(x)#out is 3D\n",
        "    # x=layers.TimeDistributed(layers.Conv2D(32,10,activation=tf.nn.gelu))(inputs)\n",
        "    # x=layers.TimeDistributed(layers.Conv2D(100,10,activation=\"tanh\"))(x)\n",
        "    # # x=layers.Dense(2,activation=\"softmax\")(x)\n",
        "    # x=(layers.Conv3D(130,4,activation=tf.nn.gelu))(x)\n",
        "    # # x=(layers.Conv3D(20,5))(x)\n",
        "    # # x=(layers.Conv3D(32,10,activation=tf.nn.gelu))(x)\n",
        "    # # x=(layers.Conv3D(100,5,activation=tf.nn.gelu))(x)\n",
        "    # print(x.shape)\n",
        "    # x=layers.TimeDistributed(layers.GlobalMaxPooling2D())(x)\n",
        "    # x=layers.TimeDistributed(layers.Flatten())(x)\n",
        "    ############\n",
        "    # x = layers.Dropout(0.3)(x)\n",
        "    print(np.shape(x))\n",
        "    # x=layers.Dense(embedDim,activation=tf.nn.gelu)(x)#is this line the issue?\n",
        "    # x=layers.Conv1D(embedDim,3,activation=tf.nn.gelu)(x)#is this line the issue?\n",
        "    print(np.shape(x))\n",
        "    x = PositionalEmbedding(\n",
        "        seqLen, x.shape[-1], name=\"frame_position_embedding\"\n",
        "    )(x)\n",
        "    # x1=TFPositionalEncoding1D(x.shape[-1])(x)\n",
        "    # x=layers.Add()([x1,x])\n",
        "    # x=x1+x\n",
        "    for _ in range(nTr):\n",
        "      # x=transformer_encoder(x, embedDim, 32, ff_dim=ff_dim, dropout=trDr)\n",
        "      # x=TransformerEncoder(embed_dim=embedDim, dense_dim=200, num_heads=numHeads)(x)\n",
        "      # x=layers.Dropout(0.3)(x)\n",
        "      x=TransformerEncoder(embed_dim=x.shape[-1], dense_dim=dense_dim2, num_heads=numHeads)(x)\n",
        "      # x=keras.layers.Attention()([x,x,x])\n",
        "    print(np.shape(x))\n",
        "    # res = layers.MultiHeadAttention(\n",
        "    #       key_dim=200, \n",
        "    #       num_heads=8, \n",
        "    #       dropout=trDr,\n",
        "    #       # kernel_regularizer=tf.keras.regularizers.l1(0.02),\n",
        "    #       # activity_regularizer=tf.keras.regularizers.l1(0.01)\n",
        "    #   )(x, x)\n",
        "    # x=layers.Add()([x,res])\n",
        "    # x = layers.GlobalAveragePooling1D()(x)\n",
        "    # x=layers.Conv1D(200,2,activation=tf.nn.gelu)(x)#is this line the issue?\n",
        "    # x=layers.Conv1D(100,2,activation=tf.nn.gelu)(x)#is this line the issue?\n",
        "    # x = layers.Dropout(0.3)(x)\n",
        "    # x = layers.Flatten()(x)\n",
        "    # x = layers.Dense(dense_dim2,activation=tf.nn.gelu)(x)\n",
        "    # x = layers.Dense(200,activation=tf.nn.gelu)(x)\n",
        "    # x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.GlobalMaxPooling1D()(x)\n",
        "    # print(np.shape(x))\n",
        "    # x = layers.Dropout(0.3)(x)\n",
        "    # x = layers.Conv1D(filters=x.shape[-1], kernel_size=1)(x)\n",
        "    # print(np.shape(x))\n",
        "    # x=layers.GlobalAveragePooling1D()(x)\n",
        "    act=\"softmax\" if classes!=2 else \"sigmoid\"\n",
        "    # x=layers.Dense(40,activation=tf.nn.gelu)(x)\n",
        "    x=layers.Dense(classes,activation=act)(x)\n",
        "    model = keras.Model(inputs, x)\n",
        "    return model"
      ],
      "metadata": {
        "id": "Fqegf--cgSFN"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data=np.random.rand(2,5,3)+2\n",
        "# print(data)\n",
        "# print(np.mean(data))\n",
        "# print(np.std(data))\n",
        "# data=layers.LayerNormalization()(data)\n",
        "# print(data)\n",
        "# print(np.mean(data))\n",
        "# print(np.std(data))"
      ],
      "metadata": {
        "id": "A3Asi1LnS7V1"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with strategy.scope(): \n",
        "with tf.device(\"/device:GPU:0\"): \n",
        "\n",
        "  # model=mainModel(embedDim=32*9,numHeads=32,classes=n_classes,dense_dim2=100,trDr=0.5,nTr=8)\n",
        "  model=mainModel(embedDim=32*11,numHeads=8,classes=n_classes,dense_dim2=4,trDr=0.5,nTr=1)"
      ],
      "metadata": {
        "id": "m6Tfm8AKpoHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d509a04-5c07-4480-e79f-7b9d8eb8e812"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 45, 128, 128, 3)\n",
            "(None, 45, 1024)\n",
            "(None, 45, 1024)\n",
            "(None, 45, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install tensorflow_addons\n",
        "%pip install tensorboard"
      ],
      "metadata": {
        "id": "vHlL2JcQGgNl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "929bb613-aa34-44f4-bd91-ae4257fa0378"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.15.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.19.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.43.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.37.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHl3GFx2kA_j",
        "outputId": "839f0efe-b98f-4712-ff97-e01b763ef5c6"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import TensorBoard\n",
        "log_dir=\"temp_log\"\n",
        "tensorboard_callback = TensorBoard(\n",
        "    log_dir=log_dir,\n",
        "    histogram_freq=1,\n",
        "    write_graph=True,\n",
        "    write_images=False,\n",
        "    update_freq=\"epoch\",\n",
        ")"
      ],
      "metadata": {
        "id": "JMHoM-W3ko3T"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "from sklearn.metrics import  precision_score,recall_score,f1_score\n",
        "from keras.metrics import Recall,Precision\n",
        "from tensorflow_addons.metrics import F1Score"
      ],
      "metadata": {
        "id": "6dVIj4uMDwz5"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with strategy.scope(): \n",
        "with tf.device(\"/device:GPU:0\"): \n",
        "  class_weight = dict()\n",
        "  class_weight[0]=1/10\n",
        "  uniq=len(trainCsv[option].unique())\n",
        "  for i in range(1,uniq):\n",
        "    class_weight[i]=(uniq-1)/10\n",
        "  metrics=['accuracy']\n",
        "  if option==\"label\":\n",
        "    metrics+=[F1Score(n_classes,threshold=0.5),Recall(),Precision()]\n",
        "  loss=\"categorical_crossentropy\" if option!=\"label\" else \"binary_crossentropy\"\n",
        "  # model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.05, nesterov=True),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  # model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.001, nesterov=True),loss=loss,metrics=['accuracy',f1_m,precision_m, recall_m])\n",
        "  model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.1),loss=loss,metrics=metrics)\n",
        "  # model.compile(optimizer=keras.optimizers.RMSprop(),loss=loss,metrics=metrics)\n",
        "  # model.compile(optimizer=\"adam\",loss=loss,metrics=metrics)\n",
        "  train_loss=[]\n",
        "  val_loss=[]\n",
        "  train_acc=[]\n",
        "  val_acc=[]"
      ],
      "metadata": {
        "id": "odagAM1GMU5B"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # with strategy.scope(): \n",
        "# import pickle\n",
        "# import _pickle as cPickle\n",
        "# with tf.device(\"/device:GPU:0\"): \n",
        "#   model = keras.models.load_model('/content/drive/MyDrive/tf_transformer_4/results2/model')\n",
        "#   with open(\"/content/drive/MyDrive/tf_transformer_4/results2/train_loss\", \"rb\") as output:\n",
        "#     train_loss=cPickle.load(output)\n",
        "#   with open(\"/content/drive/MyDrive/tf_transformer_4/results2/val_loss\", \"rb\") as output:\n",
        "#     val_loss=cPickle.load(output)\n",
        "#   with open(\"/content/drive/MyDrive/tf_transformer_4/results2/train_acc\", \"rb\") as output:\n",
        "#     train_acc=cPickle.load(output)\n",
        "#   with open(\"/content/drive/MyDrive/tf_transformer_4/results2/val_acc\", \"rb\") as output:\n",
        "#     val_acc=cPickle.load(output)\n",
        "#   trainCsv=pd.read_csv(\"/content/drive/MyDrive/tf_transformer_4/results2/trainCsv\")\n",
        "#   valCsv=pd.read_csv(\"/content/drive/MyDrive/tf_transformer_4/results2/valCsv\")\n",
        "#   training_generator = Dataset(trainCsv['Path'].values, trainCsv['classLabel'].values, **params)\n",
        "#   val_generator = Dataset(valCsv['Path'].values, valCsv['classLabel'].values, **params)"
      ],
      "metadata": {
        "id": "8-EDnL_L7WRG"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  with strategy.scope(): \n",
        "# # with strategy.scope(): \n",
        "#   epochs=20\n",
        "#   for epoch in range(epochs):\n",
        "#     start=time.time()\n",
        "#     print('Epoch: {}/{}'.format(epoch+1,epochs))\n",
        "#     count=0\n",
        "#     for i,data in enumerate(training_generator):\n",
        "#       x,y=data\n",
        "#       x=x.astype(np.float32)\n",
        "#       y=y.astype(np.float32)\n",
        "#       hist=model.fit(x,y,batch_size=batch_size,verbose=0,epochs=1)\n",
        "#       curr_acc=hist.history['accuracy']\n",
        "#       curr_loss=hist.history['loss']\n",
        "#       if count==0:\n",
        "#         train_loss.append(curr_loss[0])\n",
        "#         train_acc.append(curr_acc[0])\n",
        "#       else:\n",
        "#         train_loss[-1]+=curr_loss[0]\n",
        "#         train_acc[-1]+=curr_acc[0]\n",
        "#       count+=1\n",
        "#       gc.collect()\n",
        "#     train_loss[-1]/=count\n",
        "#     train_acc[-1]/=count\n",
        "#     count=0\n",
        "#     for i,data in enumerate(val_generator):\n",
        "#       x,y=data\n",
        "#       y_pred=model(x)\n",
        "#       curr_acc=accuracy_score(np.argmax(y,axis=1),np.argmax(y_pred,axis=1))\n",
        "#       curr_loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False,reduction=tf.keras.losses.Reduction.NONE)(y, y_pred).numpy()\n",
        "#       curr_loss=np.sum(curr_loss)\n",
        "#       curr_loss/=batch_size\n",
        "#       if count==0:\n",
        "#         val_loss.append(curr_loss)\n",
        "#         val_acc.append(curr_acc)\n",
        "#       else:\n",
        "#         val_loss[-1]+=curr_loss\n",
        "#         val_acc[-1]+=curr_acc\n",
        "#       count+=1\n",
        "#       gc.collect()\n",
        "#     val_loss[-1]/=count\n",
        "#     val_acc[-1]/=count\n",
        "#     end=time.time()\n",
        "#     gc.collect()\n",
        "#     print(\"Time:{} Training loss:{} Training accuracy:{} Validation loss:{} Validation accuracy:{}\".format(end-start,train_loss[-1],train_acc[-1],val_loss[-1],val_acc[-1]))  "
      ],
      "metadata": {
        "id": "U3oAKYAL1MXu"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(\"/device:GPU:0\"): \n",
        "  class LossAndErrorPrintingCallback(keras.callbacks.Callback):\n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "      # print(\"Batch end\")\n",
        "      gc.enable()\n",
        "      gc.collect()\n",
        "      return\n",
        "    def on_test_batch_end(self, batch, logs=None):\n",
        "      # print(\"Batch end\")\n",
        "      gc.enable()\n",
        "      gc.collect()\n",
        "      return\n",
        "    def on_predict_batch_end(self, batch, logs=None):\n",
        "      # print(\"Batch end\")\n",
        "      gc.enable()\n",
        "      gc.collect()\n",
        "      return\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "      # print(\"Batch end\")\n",
        "      gc.enable()\n",
        "      gc.collect()\n",
        "      return"
      ],
      "metadata": {
        "id": "hUUkNMcjIw0E"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(\"/device:GPU:0\"): \n",
        "# with strategy.scope(): \n",
        "  epochs=8\n",
        "  start=time.time()\n",
        "  # divider=1\n",
        "  # multiplier=2\n",
        "  # class_weight = dict()\n",
        "  # class_weight[0]=1 if option==\"label\" else 1/divider\n",
        "  # uniq=len(trainCsv[option].unique())\n",
        "  # print(uniq)\n",
        "  # for i in range(1,uniq):\n",
        "  #   class_weight[i]=(uniq-1)/divider if option==\"classLabel\" else (uniq-1)*multiplier\n",
        "  # hist=model.fit(x=training_generator,validation_data=val_generator,epochs=epochs,verbose=1, class_weight=class_weight,callbacks=[LossAndErrorPrintingCallback()])\n",
        "  hist=model.fit(x=training_generator,validation_data=val_generator,epochs=epochs,verbose=1, class_weight=class_count_dict,callbacks=[LossAndErrorPrintingCallback(),tensorboard_callback])\n",
        "  # hist=model.fit(x=training_generator,validation_data=val_generator,epochs=epochs,verbose=1, callbacks=[LossAndErrorPrintingCallback()])\n",
        "  end=time.time()\n",
        "  gc.collect()\n",
        "  val_loss+=hist.history['val_loss']\n",
        "  train_loss+=hist.history['loss']\n",
        "  val_acc+=hist.history['val_accuracy']\n",
        "  train_acc+=hist.history['accuracy']"
      ],
      "metadata": {
        "id": "kZoo6iZHEoJq",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b55ba941-d7c6-48dd-ddf0-5cfe07186837"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
            "Layer PositionalEmbedding has arguments ['self', 'sequence_length', 'output_dim']\n",
            "in `__init__` and therefore must override `get_config()`.\n",
            "\n",
            "Example:\n",
            "\n",
            "class CustomLayer(keras.layers.Layer):\n",
            "    def __init__(self, arg1, arg2):\n",
            "        super().__init__()\n",
            "        self.arg1 = arg1\n",
            "        self.arg2 = arg2\n",
            "\n",
            "    def get_config(self):\n",
            "        config = super().get_config()\n",
            "        config.update({\n",
            "            \"arg1\": self.arg1,\n",
            "            \"arg2\": self.arg2,\n",
            "        })\n",
            "        return config\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "  6/104 [>.............................] - ETA: 9:29 - loss: 199.4023 - accuracy: 0.0156WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 4.3137s vs `on_train_batch_end` time: 6.1335s). Check your callbacks.\n",
            "104/104 [==============================] - 950s 9s/step - loss: 43.6562 - accuracy: 0.3005 - val_loss: 8.1425 - val_accuracy: 0.2985\n",
            "Epoch 2/8\n",
            "104/104 [==============================] - 875s 8s/step - loss: 5.4142 - accuracy: 0.5243 - val_loss: 5.8518 - val_accuracy: 0.3233\n",
            "Epoch 3/8\n",
            "104/104 [==============================] - 885s 8s/step - loss: 2.7515 - accuracy: 0.6247 - val_loss: 5.2667 - val_accuracy: 0.3685\n",
            "Epoch 4/8\n",
            "104/104 [==============================] - 888s 9s/step - loss: 1.9386 - accuracy: 0.6767 - val_loss: 3.5857 - val_accuracy: 0.4224\n",
            "Epoch 5/8\n",
            "104/104 [==============================] - 890s 9s/step - loss: 1.3925 - accuracy: 0.7326 - val_loss: 2.8572 - val_accuracy: 0.4892\n",
            "Epoch 6/8\n",
            "104/104 [==============================] - 859s 8s/step - loss: 1.2673 - accuracy: 0.7536 - val_loss: 2.1606 - val_accuracy: 0.5409\n",
            "Epoch 7/8\n",
            "104/104 [==============================] - 854s 8s/step - loss: 1.0499 - accuracy: 0.7837 - val_loss: 1.6635 - val_accuracy: 0.5873\n",
            "Epoch 8/8\n",
            "104/104 [==============================] - 854s 8s/step - loss: 0.9659 - accuracy: 0.7993 - val_loss: 1.4550 - val_accuracy: 0.6131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(\"/device:GPU:0\"): \n",
        "# with strategy.scope(): \n",
        "  epochs=8\n",
        "  start=time.time()\n",
        "  # divider=1\n",
        "  # multiplier=2\n",
        "  # class_weight = dict()\n",
        "  # class_weight[0]=1 if option==\"label\" else 1/divider\n",
        "  # uniq=len(trainCsv[option].unique())\n",
        "  # print(uniq)\n",
        "  # for i in range(1,uniq):\n",
        "  #   class_weight[i]=(uniq-1)/divider if option==\"classLabel\" else (uniq-1)*multiplier\n",
        "  # hist=model.fit(x=training_generator,validation_data=val_generator,epochs=epochs,verbose=1, class_weight=class_weight,callbacks=[LossAndErrorPrintingCallback()])\n",
        "  hist=model.fit(x=training_generator,validation_data=val_generator,epochs=epochs,verbose=1, class_weight=class_count_dict,callbacks=[LossAndErrorPrintingCallback(),tensorboard_callback])\n",
        "  # hist=model.fit(x=training_generator,validation_data=val_generator,epochs=epochs,verbose=1, callbacks=[LossAndErrorPrintingCallback()])\n",
        "  end=time.time()\n",
        "  gc.collect()\n",
        "  val_loss+=hist.history['val_loss']\n",
        "  train_loss+=hist.history['loss']\n",
        "  val_acc+=hist.history['val_accuracy']\n",
        "  train_acc+=hist.history['accuracy']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRbQPFU3bMm-",
        "outputId": "4066651a-8682-408b-8d32-ae116fc24e18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
            "Layer PositionalEmbedding has arguments ['self', 'sequence_length', 'output_dim']\n",
            "in `__init__` and therefore must override `get_config()`.\n",
            "\n",
            "Example:\n",
            "\n",
            "class CustomLayer(keras.layers.Layer):\n",
            "    def __init__(self, arg1, arg2):\n",
            "        super().__init__()\n",
            "        self.arg1 = arg1\n",
            "        self.arg2 = arg2\n",
            "\n",
            "    def get_config(self):\n",
            "        config = super().get_config()\n",
            "        config.update({\n",
            "            \"arg1\": self.arg1,\n",
            "            \"arg2\": self.arg2,\n",
            "        })\n",
            "        return config\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "104/104 [==============================] - 957s 9s/step - loss: 0.8120 - accuracy: 0.8182 - val_loss: 1.3688 - val_accuracy: 0.6401\n",
            "Epoch 2/8\n",
            "104/104 [==============================] - 931s 9s/step - loss: 0.7822 - accuracy: 0.8398 - val_loss: 1.1434 - val_accuracy: 0.6864\n",
            "Epoch 3/8\n",
            "104/104 [==============================] - 929s 9s/step - loss: 0.6756 - accuracy: 0.8462 - val_loss: 1.3166 - val_accuracy: 0.6638\n",
            "Epoch 4/8\n",
            "104/104 [==============================] - 926s 9s/step - loss: 0.6026 - accuracy: 0.8618 - val_loss: 1.0950 - val_accuracy: 0.7037\n",
            "Epoch 5/8\n",
            "104/104 [==============================] - 929s 9s/step - loss: 0.5155 - accuracy: 0.8819 - val_loss: 1.0555 - val_accuracy: 0.7166\n",
            "Epoch 6/8\n",
            "104/104 [==============================] - 926s 9s/step - loss: 0.4774 - accuracy: 0.8924 - val_loss: 1.1440 - val_accuracy: 0.7069\n",
            "Epoch 7/8\n",
            "104/104 [==============================] - 938s 9s/step - loss: 0.4381 - accuracy: 0.9011 - val_loss: 1.1366 - val_accuracy: 0.7155\n",
            "Epoch 8/8\n",
            " 69/104 [==================>...........] - ETA: 4:08 - loss: 0.4021 - accuracy: 0.9090"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this seems fast "
      ],
      "metadata": {
        "id": "1PGYEBR7ZHDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4Dl5Mmo71ZKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard --logdir temp_log"
      ],
      "metadata": {
        "id": "VnTsA6G8lZDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# with tf.device(\"/device:GPU:0\"):\n",
        "#   model.save('/content/drive/MyDrive/tf_transformer_5/results/model')\n",
        "#   with open(\"/content/drive/MyDrive/tf_transformer_5/results/train_loss\", \"wb\") as output:\n",
        "#     pickle.dump(train_loss,output)\n",
        "#   with open(\"/content/drive/MyDrive/tf_transformer_5/results/val_loss\", \"wb\") as output:\n",
        "#     pickle.dump(val_loss,output)\n",
        "#   with open(\"/content/drive/MyDrive/tf_transformer_5/results/train_acc\", \"wb\") as output:\n",
        "#     pickle.dump(train_acc,output)\n",
        "#   with open(\"/content/drive/MyDrive/tf_transformer_5/results/val_acc\", \"wb\") as output:\n",
        "#     pickle.dump(val_acc,output)\n"
      ],
      "metadata": {
        "id": "7a7oeaXkokhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with tf.device(\"/device:GPU:0\"):\n",
        "#   trainCsv.to_csv(\"/content/drive/MyDrive/tf_transformer_5/results/trainCsv\")\n",
        "#   testCsv.to_csv(\"/content/drive/MyDrive/tf_transformer_5/results/testCsv\")\n",
        "#   valCsv.to_csv(\"/content/drive/MyDrive/tf_transformer_5/results/valCsv\")"
      ],
      "metadata": {
        "id": "ITdozBRdpbdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "pE7h3TtoALXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# with tf.device(\"/device:GPU:0\"):\n",
        "#   model.save('/content/drive/MyDrive/tf_transformer_4/results2/model')\n",
        "#   with open(\"/content/drive/MyDrive/tf_transformer_4/results2/train_loss\", \"wb\") as output:\n",
        "#     pickle.dump(train_loss,output)\n",
        "#   with open(\"/content/drive/MyDrive/tf_transformer_4/results2/val_loss\", \"wb\") as output:\n",
        "#     pickle.dump(val_loss,output)\n",
        "#   with open(\"/content/drive/MyDrive/tf_transformer_4/results2/train_acc\", \"wb\") as output:\n",
        "#     pickle.dump(train_acc,output)\n",
        "#   with open(\"/content/drive/MyDrive/tf_transformer_4/results2/val_acc\", \"wb\") as output:\n",
        "#     pickle.dump(val_acc,output)\n",
        "#   trainCsv.to_csv(\"/content/drive/MyDrive/tf_transformer_4/results2/trainCsv\")\n",
        "#   valCsv.to_csv(\"/content/drive/MyDrive/tf_transformer_4/results2/valCsv\")"
      ],
      "metadata": {
        "id": "i8EambIzI67T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # for data in val_generator:\n",
        "# for data in training_generator:\n",
        "#   print(np.count_nonzero(data[0]))\n",
        "#   # break "
      ],
      "metadata": {
        "id": "mJHUZ2xwC07_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.listdir(\"/content/drive/MyDrive/dcsass/DCSASS Dataset\")"
      ],
      "metadata": {
        "id": "plt85Z8pWW92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with tf.device(\"/device:GPU:0\"):\n",
        "#   # del model\n",
        "#   gc.collect()"
      ],
      "metadata": {
        "id": "XAOEYX3YTxcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "99ZzQc7TRVqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DHtj68UwqQWC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}